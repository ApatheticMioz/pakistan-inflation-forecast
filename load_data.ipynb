{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be4c4b0c-a3b7-4ae3-83a5-eb0d5e2fb4c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded t_bills.csv successfully.\n",
      "Loaded seasonal_worker_remittance.csv successfully.\n",
      "Loaded REER.csv successfully.\n",
      "Loaded quaterly_gdp_2015.csv successfully.\n",
      "Loaded policy_rate.csv successfully.\n",
      "Loaded m2_broad_money.csv successfully.\n",
      "Loaded kibor_kibid.csv successfully.\n",
      "Loaded inflation_base_2015.csv successfully.\n",
      "Loaded inflation_base_2007.csv successfully.\n",
      "Loaded gdp_domestic_2005.csv successfully.\n",
      "Loaded foreign_invest_sectors.csv successfully.\n",
      "Loaded foreign_invest_countires.csv successfully.\n",
      "Loaded exchange_rate.csv successfully.\n",
      "Loaded consumer_confidence_survey.csv successfully.\n",
      "Loaded country_wise_remittance.csv successfully.\n",
      "Loaded borrow_loans.csv successfully.\n",
      "Loaded LSM_QIM_2015.csv successfully.\n",
      "Loaded LSM_QIM_2005.csv successfully.\n",
      "Loaded gold_foreign_exchange_reserves.csv successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_20348\\2048360984.py:22: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path, quotechar='\"', header=0)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "data_folder = 'Data'\n",
    "\n",
    "# List of files in this category\n",
    "standard_files = [\n",
    "    't_bills.csv', 'seasonal_worker_remittance.csv', 'REER.csv',\n",
    "    'quaterly_gdp_2015.csv', 'policy_rate.csv', 'm2_broad_money.csv',\n",
    "    'kibor_kibid.csv', 'inflation_base_2015.csv', 'inflation_base_2007.csv',\n",
    "    'gdp_domestic_2005.csv', 'foreign_invest_sectors.csv',\n",
    "    'foreign_invest_countires.csv', 'exchange_rate.csv',\n",
    "    'consumer_confidence_survey.csv', 'country_wise_remittance.csv',\n",
    "    'borrow_loans.csv', 'LSM_QIM_2015.csv', 'LSM_QIM_2005.csv',\n",
    "    'gold_foreign_exchange_reserves.csv'\n",
    "]\n",
    "\n",
    "for filename in standard_files:\n",
    "    file_path = os.path.join(data_folder, filename)\n",
    "    try:\n",
    "        # Use header=0 (default) and specify quotechar\n",
    "        df = pd.read_csv(file_path, quotechar='\"', header=0)\n",
    "        print(f\"Loaded {filename} successfully.\")\n",
    "        # print(df.head(2)) # Optional: print first few rows to verify\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {filename}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9727bb02-26d8-4d53-be26-49535bcf9766",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded transport_and_communications.csv successfully.\n",
      "Loaded trade_and_payments.csv successfully.\n",
      "Loaded public_debt.csv successfully.\n",
      "Loaded population,_labor_force_and_employment.csv successfully.\n",
      "Loaded money_and_credit.csv successfully.\n",
      "Loaded manufacturing_and_mining.csv successfully.\n",
      "Loaded inflation.csv successfully.\n",
      "Loaded health_and_nutrition.csv successfully.\n",
      "Loaded growth_and_investment.csv successfully.\n",
      "Loaded fiscal_development.csv successfully.\n",
      "Loaded energy.csv successfully.\n",
      "Loaded education.csv successfully.\n",
      "Loaded economic_and_social_indicators.csv successfully.\n",
      "Loaded capital_markets_and_corporate_sector.csv successfully.\n",
      "Loaded agriculture.csv successfully.\n"
     ]
    }
   ],
   "source": [
    "# List of files in this category\n",
    "multi_header_files = [\n",
    "    'transport_and_communications.csv', 'trade_and_payments.csv',\n",
    "    'public_debt.csv', 'population,_labor_force_and_employment.csv',\n",
    "    'money_and_credit.csv', 'manufacturing_and_mining.csv',\n",
    "    'inflation.csv', 'health_and_nutrition.csv', 'growth_and_investment.csv',\n",
    "    'fiscal_development.csv', 'energy.csv', 'education.csv',\n",
    "    'economic_and_social_indicators.csv',\n",
    "    'capital_markets_and_corporate_sector.csv', 'agriculture.csv'\n",
    "]\n",
    "\n",
    "for filename in multi_header_files:\n",
    "    file_path = os.path.join(data_folder, filename)\n",
    "    try:\n",
    "        # Use header=0 (default)\n",
    "        df = pd.read_csv(file_path, header=0)\n",
    "        print(f\"Loaded {filename} successfully.\")\n",
    "        # print(df.head(2)) # Optional: print first few rows to verify\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {filename}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e4fccfe5-e2c4-4057-8538-9552940dd207",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded usa_inflation.csv successfully.\n",
      "Loaded uk_inflation.csv successfully.\n",
      "Loaded uae_inflation.csv successfully.\n",
      "Loaded spain_inflation.csv successfully.\n",
      "Loaded pakistan_inflation.csv successfully.\n",
      "Loaded netherlands_inflation.csv successfully.\n",
      "Loaded italy_inflation.csv successfully.\n",
      "Loaded germany_inflation.csv successfully.\n",
      "Loaded china_inflation.csv successfully.\n",
      "Loaded bangladesh_inflation.csv successfully.\n",
      "Loaded afghanistan_inflation.csv successfully.\n"
     ]
    }
   ],
   "source": [
    "# List of files in this category\n",
    "inflation_files = [\n",
    "    'usa_inflation.csv', 'uk_inflation.csv', 'uae_inflation.csv',\n",
    "    'spain_inflation.csv', 'pakistan_inflation.csv',\n",
    "    'netherlands_inflation.csv', 'italy_inflation.csv',\n",
    "    'germany_inflation.csv', 'china_inflation.csv',\n",
    "    'bangladesh_inflation.csv', 'afghanistan_inflation.csv'\n",
    "]\n",
    "\n",
    "for filename in inflation_files:\n",
    "    file_path = os.path.join(data_folder, filename)\n",
    "    try:\n",
    "        # Use header=0 (default)\n",
    "        df = pd.read_csv(file_path, header=0)\n",
    "        print(f\"Loaded {filename} successfully.\")\n",
    "        # print(df.head(2)) # Optional: print first few rows to verify\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {filename}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "72066b36-fd34-403a-80f2-f444bce730c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded CMO_historical_data_monthly.csv successfully.\n",
      "Loaded CMO_historical_data_indices.csv successfully.\n"
     ]
    }
   ],
   "source": [
    "# CMO_historical_data_monthly.csv: Header seems to be on row 5 (index 4)\n",
    "file_path_monthly = os.path.join(data_folder, 'CMO_historical_data_monthly.csv')\n",
    "try:\n",
    "    df_monthly = pd.read_csv(file_path_monthly, header=4) # header is 0-indexed\n",
    "    print(f\"Loaded CMO_historical_data_monthly.csv successfully.\")\n",
    "    # print(df_monthly.head(2)) # Optional: print first few rows to verify\n",
    "except Exception as e:\n",
    "    print(f\"Error loading CMO_historical_data_monthly.csv: {e}\")\n",
    "\n",
    "# CMO_historical_data_indices.csv: Header seems to be on row 6 (index 5)\n",
    "file_path_indices = os.path.join(data_folder, 'CMO_historical_data_indices.csv')\n",
    "try:\n",
    "    df_indices = pd.read_csv(file_path_indices, header=5) # header is 0-indexed\n",
    "    print(f\"Loaded CMO_historical_data_indices.csv successfully.\")\n",
    "    # print(df_indices.head(2)) # Optional: print first few rows to verify\n",
    "except Exception as e:\n",
    "    print(f\"Error loading CMO_historical_data_indices.csv: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2f5f5398-e9f4-4eec-a98f-e3ac1394f32c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to write detailed overview to: data_overview_output_detailed.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_20348\\1917229161.py:92: FutureWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  df = pd.read_csv(\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_20348\\1917229161.py:92: FutureWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  df = pd.read_csv(\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_20348\\1917229161.py:92: FutureWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  df = pd.read_csv(\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_20348\\1917229161.py:92: FutureWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  df = pd.read_csv(\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_20348\\1917229161.py:92: FutureWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  df = pd.read_csv(\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_20348\\1917229161.py:92: FutureWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  df = pd.read_csv(\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_20348\\1917229161.py:92: FutureWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  df = pd.read_csv(\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_20348\\1917229161.py:92: FutureWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  df = pd.read_csv(\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_20348\\1917229161.py:92: FutureWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  df = pd.read_csv(\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_20348\\1917229161.py:92: FutureWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  df = pd.read_csv(\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_20348\\1917229161.py:92: FutureWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  df = pd.read_csv(\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_20348\\1917229161.py:92: FutureWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  df = pd.read_csv(\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_20348\\1917229161.py:92: FutureWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  df = pd.read_csv(\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_20348\\1917229161.py:92: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_20348\\1917229161.py:92: FutureWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  df = pd.read_csv(\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_20348\\1917229161.py:92: FutureWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  df = pd.read_csv(\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_20348\\1917229161.py:92: FutureWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  df = pd.read_csv(\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_20348\\1917229161.py:92: FutureWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  df = pd.read_csv(\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_20348\\1917229161.py:92: FutureWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  df = pd.read_csv(\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_20348\\1917229161.py:92: FutureWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  df = pd.read_csv(\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_20348\\1917229161.py:149: FutureWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  df = pd.read_csv(\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_20348\\1917229161.py:149: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df = pd.read_csv(\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_20348\\1917229161.py:149: FutureWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  df = pd.read_csv(\n",
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_20348\\1917229161.py:149: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df = pd.read_csv(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Detailed data overview has been saved to 'data_overview_output_detailed.txt'\n",
      "\n",
      "First few lines of the output file:\n",
      "--- Loading Standard CSV Files ---\n",
      "Successfully loaded: t_bills.csv\n",
      "Successfully loaded: seasonal_worker_remittance.csv\n",
      "Successfully loaded: REER.csv\n",
      "Successfully loaded: quaterly_gdp_2015.csv\n",
      "Successfully loaded: policy_rate.csv\n",
      "Successfully loaded: m2_broad_money.csv\n",
      "Successfully loaded: kibor_kibid.csv\n",
      "Successfully loaded: inflation_base_2015.csv\n",
      "Successfully loaded: inflation_base_2007.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import sys # Import sys module for redirecting stdout\n",
    "import io  # Import io for capturing df.info()\n",
    "import re # Import regex for identifying year columns\n",
    "import numpy as np # Import numpy for numeric types check\n",
    "\n",
    "# Define the path to your data folder\n",
    "data_folder = 'Data'\n",
    "# Define the output file name\n",
    "output_filename = 'data_overview_output_detailed.txt'\n",
    "\n",
    "# --- File Categorization (Based on previous analysis) ---\n",
    "\n",
    "# Common strings representing missing values\n",
    "common_na_values = ['..', 'no data', 'NaN', 'NA', 'na', '-', ' ', '', '<NA>'] # Added <NA>\n",
    "\n",
    "# 1. Standard CSV Files (Comma-separated, Quoted Fields, Header=0)\n",
    "# These have a consistent structure with 'Observation Date' and 'Observation Value'\n",
    "standard_files = [\n",
    "    't_bills.csv', 'seasonal_worker_remittance.csv', 'REER.csv',\n",
    "    'quaterly_gdp_2015.csv', 'policy_rate.csv', 'm2_broad_money.csv',\n",
    "    'kibor_kibid.csv', 'inflation_base_2015.csv', 'inflation_base_2007.csv',\n",
    "    'gdp_domestic_2005.csv', 'foreign_invest_sectors.csv',\n",
    "    'foreign_invest_countires.csv', 'exchange_rate.csv',\n",
    "    'consumer_confidence_survey.csv', 'country_wise_remittance.csv',\n",
    "    'borrow_loans.csv', 'LSM_QIM_2015.csv', 'LSM_QIM_2005.csv',\n",
    "    'gold_foreign_exchange_reserves.csv'\n",
    "]\n",
    "# Columns to parse as dates in standard files\n",
    "standard_date_cols = ['Observation Date']\n",
    "\n",
    "# 2. Wide Time-Series Files (Header=0, Years as Columns)\n",
    "# These typically have 'Sectors', 'Sub-Sectors-Level1/2' and then year columns\n",
    "wide_files = [\n",
    "    'transport_and_communications.csv', 'trade_and_payments.csv',\n",
    "    'public_debt.csv', 'population,_labor_force_and_employment.csv',\n",
    "    'money_and_credit.csv', 'manufacturing_and_mining.csv',\n",
    "    'inflation.csv', 'health_and_nutrition.csv', 'growth_and_investment.csv',\n",
    "    'fiscal_development.csv', 'energy.csv', 'education.csv',\n",
    "    'economic_and_social_indicators.csv',\n",
    "    'capital_markets_and_corporate_sector.csv', 'agriculture.csv',\n",
    "    # Adding inflation files here as they also have years as columns\n",
    "    'usa_inflation.csv', 'uk_inflation.csv', 'uae_inflation.csv',\n",
    "    'spain_inflation.csv', 'pakistan_inflation.csv',\n",
    "    'netherlands_inflation.csv', 'italy_inflation.csv',\n",
    "    'germany_inflation.csv', 'china_inflation.csv',\n",
    "    'bangladesh_inflation.csv', 'afghanistan_inflation.csv'\n",
    "]\n",
    "\n",
    "# 3. World Bank Commodity Data (Metadata Above Header)\n",
    "cmo_files = {\n",
    "    'CMO_historical_data_monthly.csv': {'header': 4, 'date_col': 0}, # Header row index, date col index\n",
    "    'CMO_historical_data_indices.csv': {'header': 5, 'date_col': 0}  # Header row index, date col index\n",
    "}\n",
    "\n",
    "# 4. Empty Files (To be skipped)\n",
    "empty_files = [\n",
    "    'social_protection.csv',\n",
    "    'information_technology_and_telecommunication.csv'\n",
    "]\n",
    "\n",
    "# --- Function to identify year-like columns ---\n",
    "def get_year_columns(df):\n",
    "    year_cols = []\n",
    "    # Regex to match 4 digits possibly separated by hyphen/slash (e.g., 1999, 2000-01)\n",
    "    # Updated regex to be more flexible with column names\n",
    "    year_pattern = re.compile(r'^(?:\\d{4}(?:[-\\/]\\d{2,4})?|\\d{4})$')\n",
    "    for col in df.columns:\n",
    "        # Ensure column name is treated as a string\n",
    "        col_str = str(col)\n",
    "        if year_pattern.match(col_str):\n",
    "            year_cols.append(col) # Keep original column name (could be int or str)\n",
    "    return year_cols\n",
    "\n",
    "# --- Redirect Output to File ---\n",
    "original_stdout = sys.stdout # Save a reference to the original standard output\n",
    "\n",
    "print(f\"Attempting to write detailed overview to: {output_filename}\")\n",
    "\n",
    "try:\n",
    "    with open(output_filename, 'w', encoding='utf-8') as f:\n",
    "        sys.stdout = f # Change the standard output to the file we created.\n",
    "\n",
    "        # --- Load DataFrames ---\n",
    "        dataframes = {} # Dictionary to store the loaded dataframes\n",
    "\n",
    "        print(\"--- Loading Standard CSV Files ---\")\n",
    "        for filename in standard_files:\n",
    "            file_path = os.path.join(data_folder, filename)\n",
    "            try:\n",
    "                df = pd.read_csv(\n",
    "                    file_path,\n",
    "                    quotechar='\"',\n",
    "                    header=0,\n",
    "                    na_values=common_na_values,\n",
    "                    parse_dates=standard_date_cols,\n",
    "                    infer_datetime_format=True,\n",
    "                    dayfirst=True, # Assuming day comes first in dates like '26-Mar-2025'\n",
    "                    keep_default_na=True # Keep default NaN recognition\n",
    "                )\n",
    "                # Attempt to convert Observation Value to numeric after load\n",
    "                if 'Observation Value' in df.columns:\n",
    "                   df['Observation Value'] = pd.to_numeric(df['Observation Value'], errors='coerce')\n",
    "\n",
    "                dataframes[filename] = df\n",
    "                print(f\"Successfully loaded: {filename}\")\n",
    "            except FileNotFoundError:\n",
    "                print(f\"Error: File not found at {file_path}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading {filename}: {e}\")\n",
    "\n",
    "        print(\"\\n--- Loading Wide Time-Series Files ---\")\n",
    "        for filename in wide_files:\n",
    "            file_path = os.path.join(data_folder, filename)\n",
    "            try:\n",
    "                df = pd.read_csv(\n",
    "                    file_path,\n",
    "                    header=0,\n",
    "                    na_values=common_na_values,\n",
    "                    keep_default_na=True\n",
    "                )\n",
    "                # Identify and convert year columns to numeric after load\n",
    "                year_columns = get_year_columns(df)\n",
    "                if year_columns:\n",
    "                    print(f\"Found potential year columns in {filename}: {year_columns}\")\n",
    "                    for col in year_columns:\n",
    "                         # Check if column still exists (might be removed if all NA)\n",
    "                        if col in df.columns:\n",
    "                            # Convert column to numeric, coercing errors to NaN\n",
    "                            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "                else:\n",
    "                     print(f\"Could not identify year columns automatically in {filename}\")\n",
    "\n",
    "                dataframes[filename] = df\n",
    "                print(f\"Successfully loaded: {filename}\")\n",
    "            except FileNotFoundError:\n",
    "                print(f\"Error: File not found at {file_path}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading {filename}: {e}\")\n",
    "\n",
    "        print(\"\\n--- Loading CMO Files ---\")\n",
    "        for filename, params in cmo_files.items():\n",
    "            file_path = os.path.join(data_folder, filename)\n",
    "            try:\n",
    "                # Specify the date column index for parsing\n",
    "                date_col_list = [params['date_col']] if params['date_col'] is not None else None\n",
    "\n",
    "                df = pd.read_csv(\n",
    "                    file_path,\n",
    "                    header=params['header'],\n",
    "                    na_values=common_na_values,\n",
    "                    parse_dates=date_col_list,\n",
    "                    infer_datetime_format=True,\n",
    "                    keep_default_na=True\n",
    "                 )\n",
    "                # Convert all other columns to numeric (assuming they should be)\n",
    "                # Handle potential case where date_col is None or invalid index\n",
    "                date_col_actual = df.columns[params['date_col']] if (params['date_col'] is not None and params['date_col'] < len(df.columns)) else None\n",
    "                data_cols = df.columns.drop(date_col_actual) if date_col_actual else df.columns\n",
    "\n",
    "                for col in data_cols:\n",
    "                     if col in df.columns: # Check if column exists\n",
    "                        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "\n",
    "                dataframes[filename] = df\n",
    "                print(f\"Successfully loaded: {filename}\")\n",
    "            except FileNotFoundError:\n",
    "                print(f\"Error: File not found at {file_path}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading {filename}: {e}\")\n",
    "\n",
    "        print(f\"\\n--- Skipping Empty Files: {', '.join(empty_files)} ---\")\n",
    "\n",
    "        print(f\"\\nTotal DataFrames loaded: {len(dataframes)}\")\n",
    "\n",
    "        # --- Displaying Detailed Data Overview ---\n",
    "\n",
    "        print(\"\\n\\n--- Displaying Detailed DataFrame Overviews ---\")\n",
    "\n",
    "        # Set display options for better viewing in the output file\n",
    "        pd.set_option('display.max_rows', 200) # Show even more rows\n",
    "        pd.set_option('display.max_columns', 60) # Show more columns\n",
    "        pd.set_option('display.width', 1500) # Wider display for less wrapping\n",
    "\n",
    "        for filename, df in dataframes.items():\n",
    "            print(f\"\\n\\n{'='*80}\")\n",
    "            print(f\"   Dataset: {filename}\")\n",
    "            print(f\"{'='*80}\")\n",
    "\n",
    "            print(\"\\n--- First 20 Rows (head) ---\")\n",
    "            # Use to_string() to prevent truncation in the output file\n",
    "            print(df.head(20).to_string())\n",
    "\n",
    "            print(\"\\n--- Last 10 Rows (tail) ---\")\n",
    "            print(df.tail(10).to_string())\n",
    "\n",
    "            print(\"\\n--- DataFrame Info (info) ---\")\n",
    "            # Use buffer to capture info output as string for printing\n",
    "            buffer = io.StringIO()\n",
    "            df.info(buf=buffer, verbose=True) # Use verbose=True for more details\n",
    "            info_str = buffer.getvalue()\n",
    "            print(info_str)\n",
    "\n",
    "            print(\"\\n--- Missing Value Counts (isnull().sum()) ---\")\n",
    "            print(df.isnull().sum())\n",
    "\n",
    "            print(\"\\n--- Unique Value Counts (nunique()) ---\")\n",
    "            print(df.nunique())\n",
    "\n",
    "            print(\"\\n--- Descriptive Statistics (describe include='all') ---\")\n",
    "            # Use include='all' without the problematic argument\n",
    "            try:\n",
    "                 # Attempt to describe all columns, handling potential errors for mixed types\n",
    "                 # Explicitly convert datetime columns to object for describe() if needed\n",
    "                 df_desc = df.copy()\n",
    "                 for col in df_desc.select_dtypes(include=[np.datetime64]):\n",
    "                     df_desc[col] = df_desc[col].astype(str) # Convert datetime to string for describe\n",
    "                 print(df_desc.describe(include='all'))\n",
    "            except Exception as e:\n",
    "                print(f\"Could not generate full describe() for {filename}: {e}\")\n",
    "                # Fallback to describing only numeric columns\n",
    "                try:\n",
    "                    print(\"\\n--- Descriptive Statistics (describe - numeric only) ---\")\n",
    "                    print(df.describe()) # Default is numeric only\n",
    "                except Exception as e_num:\n",
    "                     print(f\"Could not generate numeric describe() for {filename}: {e_num}\")\n",
    "\n",
    "            print(\"\\n--- Value Counts for Categorical Columns (Top 50 unique values shown if <= 50 total unique) ---\")\n",
    "            # Select columns with 'object' dtype or 'category' dtype\n",
    "            cat_cols = df.select_dtypes(include=['object', 'category']).columns\n",
    "            for col in cat_cols:\n",
    "                num_unique = df[col].nunique()\n",
    "                if num_unique <= 50: # Only print value_counts if not excessively many unique values\n",
    "                    print(f\"\\nValue Counts for Column: '{col}' ({num_unique} unique values)\")\n",
    "                    print(df[col].value_counts().to_string())\n",
    "                else:\n",
    "                    print(f\"\\nSkipping value counts for Column: '{col}' ({num_unique} unique values > 50)\")\n",
    "\n",
    "\n",
    "        print(\"\\n\\n--- End of Detailed Data Overview ---\")\n",
    "\n",
    "# --- Restore Original Output ---\n",
    "finally: # Ensure stdout is reset even if errors occur\n",
    "    sys.stdout = original_stdout\n",
    "\n",
    "print(f\"\\nDetailed data overview has been saved to '{output_filename}'\")\n",
    "# Optional: Print a few lines from the file to confirm writing\n",
    "try:\n",
    "    with open(output_filename, 'r', encoding='utf-8') as f_check:\n",
    "        print(\"\\nFirst few lines of the output file:\")\n",
    "        for _ in range(10): # Print more lines for confirmation\n",
    "            line = f_check.readline()\n",
    "            if not line:\n",
    "                break\n",
    "            print(line, end='')\n",
    "except FileNotFoundError:\n",
    "    print(f\"Could not read back the output file '{output_filename}' for confirmation.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error reading back output file: {e}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
